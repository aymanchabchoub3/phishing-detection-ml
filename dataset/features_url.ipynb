{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2870b0",
   "metadata": {},
   "source": [
    "# URL-Based Phishing Detection Feature Extraction\n",
    "\n",
    "This notebook demonstrates how to extract 30 heuristic features from a URL to help detect phishing websites. The workflow is organized as follows:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Overview & Imports\n",
    "\n",
    "We introduce the problem: **phishing detection using URL-based features**. The notebook lists all required libraries for lexical analysis, HTTP/WHOIS lookups, and web parsing.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. URLFeature Class\n",
    "\n",
    "A `URLFeature` class is defined to:\n",
    "- Store the URL and its parsed components.\n",
    "- Fetch HTTP and WHOIS data.\n",
    "- Compute all 30 features, each indicating if a specific phishing heuristic is triggered (1 = suspicious, 0 = benign).\n",
    "\n",
    "---\n",
    "\n",
    "## 3–7. Feature Extraction Methods\n",
    "\n",
    "Features are grouped by type:\n",
    "- **Lexical Heuristics (1–7):** Analyze URL structure (e.g., length, use of IP, suspicious symbols).\n",
    "- **Scheme & WHOIS (8–12):** Check HTTPS usage, domain age, abnormal content.\n",
    "- **HTML/JS Content (18–23):** Look for suspicious HTML/JavaScript patterns.\n",
    "- **Domain Age & Traffic (24–26):** Use WHOIS and Alexa data for domain reputation.\n",
    "- **External Checks (27–30):** Google indexing, PageRank, and known bad domains.\n",
    "\n",
    "Each feature is implemented as a method in the class.\n",
    "\n",
    "---\n",
    "\n",
    "## 8. Test Harness\n",
    "\n",
    "A helper function allows you to quickly test feature extraction on any URL, printing the 0/1 results for all features.\n",
    "\n",
    "---\n",
    "\n",
    "**Summary:**  \n",
    "This notebook provides a modular, extensible framework for extracting phishing-relevant features from URLs, suitable for use in machine learning or rule-based phishing detection systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce212e",
   "metadata": {},
   "source": [
    "# 1. Overview & Imports\n",
    "\n",
    "**Purpose:**  \n",
    "We’ll build a `URLFeature` class that computes 30 URL‑based signals (e.g. URL length, IP use, domain age) to help detect phishing. Each signal returns **1** if it’s “suspicious” by heuristic, else **0** (benign).\n",
    "\n",
    "**Key Libraries:**\n",
    "- `ipaddress`, `re`, `socket` for URL lexical checks  \n",
    "- `requests`, `urllib`, `whois` for HTTP + WHOIS lookups  \n",
    "- `BeautifulSoup` (optional) for parsing HTML if needed  \n",
    "- `googlesearch` to check if the URL is indexed by Google  \n",
    "- `datetime` to compute domain age  \n",
    "- `urlparse` to break the URL into parts  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba22297",
   "metadata": {},
   "source": [
    "## 3. Python Imports & URLFeature Class Definition\n",
    "\n",
    "The first Python cell imports all the libraries needed for URL analysis and defines the skeleton of the `URLFeature` class.\n",
    "\n",
    "**Imports:**\n",
    "- `ipaddress`: Checks if a URL uses an IP address (common in phishing).\n",
    "- `re`: Regular expressions for pattern matching in URLs and HTML.\n",
    "- `urllib.request`: Used for fetching data from the web (e.g., Alexa rank).\n",
    "- `BeautifulSoup`: Parses HTML content to extract features.\n",
    "- `socket`: Handles DNS lookups and network operations.\n",
    "- `requests`: Makes HTTP requests to fetch web pages.\n",
    "- `googlesearch`: Checks if a URL is indexed by Google.\n",
    "- `whois`: Retrieves domain registration info (WHOIS data).\n",
    "- `datetime`: Handles date calculations (e.g., domain age).\n",
    "- `urlparse`: Breaks URLs into components (scheme, domain, path, etc.).\n",
    "\n",
    "**Class Skeleton:**\n",
    "- Defines a `URLFeature` class to encapsulate all feature extraction logic.\n",
    "- The `features` list will store the 30 heuristic features for each URL.\n",
    "- The class will later be expanded with methods to extract each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1cce4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipaddress            # Library to handle and validate IP addresses\n",
    "import re                   # Regular expressions for pattern matching\n",
    "import urllib.request       # For opening URLs (used in Alexa rank lookup)\n",
    "from bs4 import BeautifulSoup  # HTML parser to extract data from pages\n",
    "import socket               # Network operations (e.g. DNS lookups)\n",
    "import requests             # HTTP library to fetch page content\n",
    "from googlesearch import search  # To check Google indexing via search queries\n",
    "import whois                # To retrieve WHOIS domain registration info\n",
    "from datetime import date, datetime  # Date handling for domain age calculations\n",
    "from urllib.parse import urlparse  # To parse URL components\n",
    "\n",
    "\n",
    "class URLFeature:            # Define the URLFeature class\n",
    "    features = []           # Class variable to hold computed feature values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c2c18",
   "metadata": {},
   "source": [
    "## URLFeature Class Constructor: Initialization & Feature Extraction\n",
    "\n",
    "This cell defines the `__init__` method (constructor) for the `URLFeature` class. Here’s a breakdown of its workflow:\n",
    "\n",
    "- **Initialization:**\n",
    "    - Stores the input URL and prepares placeholders for the domain, WHOIS data, parsed URL, HTTP response, and HTML content.\n",
    "    - Tries to fetch the web page (`requests.get`) and parse its HTML (`BeautifulSoup`). If this fails (e.g., network error), it continues without crashing.\n",
    "    - Parses the URL into components (scheme, domain, path, etc.) using `urlparse`.\n",
    "    - Extracts the domain (host) and attempts a WHOIS lookup for registration details.\n",
    "\n",
    "- **Feature Extraction:**\n",
    "    - Sequentially calls each feature extraction method (e.g., `UsingIp`, `longUrl`, `shortUrl`, etc.).\n",
    "    - Appends the result (0 = benign, 1 = suspicious) to the `features` list for each heuristic.\n",
    "    - This design ensures that all features are computed and stored as soon as a `URLFeature` object is created.\n",
    "\n",
    "**Why this approach?**  \n",
    "By handling network and parsing errors gracefully, the constructor ensures robust feature extraction even if some data sources are unavailable. This is important for large-scale or automated analysis (like on Kaggle), where some URLs may be unreachable or malformed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de282a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, url):                                      # Constructor takes a URL string\n",
    "    self.features = []                                       # Initialize instance feature list\n",
    "    self.url = url                                           # Store original URL\n",
    "    self.domain = \"\"                                         # Placeholder for the domain part\n",
    "    self.whois_response = \"\"                                 # Placeholder for WHOIS lookup data\n",
    "    self.urlparse = \"\"                                       # Placeholder for parsed URL object\n",
    "    self.response = \"\"                                       # Placeholder for HTTP response\n",
    "    self.soup = \"\"                                           # Placeholder for BeautifulSoup object\n",
    "\n",
    "    try:\n",
    "        self.response = requests.get(url)                    # Attempt HTTP GET request\n",
    "        self.soup = BeautifulSoup(response.text, 'html.parser')  # Parse HTML on success\n",
    "    except:                                                  \n",
    "        pass                                                # Ignore errors (e.g. network issues)\n",
    "\n",
    "    try:\n",
    "        self.urlparse = urlparse(url)                        # Parse URL into components\n",
    "        self.domain = self.urlparse.netloc                   # Extract domain (host) portion\n",
    "    except:\n",
    "        pass                                                # Ignore parsing errors\n",
    "\n",
    "    try:\n",
    "        self.whois_response = whois.whois(self.domain)       # Perform WHOIS lookup on domain\n",
    "    except:\n",
    "        pass                                                # Ignore WHOIS failures\n",
    "\n",
    "    # Sequentially compute each feature, appending its result to the features list\n",
    "    self.features.append(self.UsingIp())                     \n",
    "    self.features.append(self.longUrl())                     \n",
    "    self.features.append(self.shortUrl())                    \n",
    "    self.features.append(self.symbol())                      \n",
    "    self.features.append(self.redirecting())                 \n",
    "    self.features.append(self.prefixSuffix())                \n",
    "    self.features.append(self.SubDomains())                  \n",
    "    self.features.append(self.Hppts())                       \n",
    "    self.features.append(self.DomainRegLen())                \n",
    "\n",
    "    # … (favicon code commented out in original)\n",
    "    self.features.append(self.NonStdPort())                  \n",
    "    self.features.append(self.HTTPSDomainURL())              \n",
    "\n",
    "    # … (several feature methods commented out in original)\n",
    "\n",
    "    self.features.append(self.AbnormalURL())                 \n",
    "    self.features.append(self.WebsiteForwarding())           \n",
    "    self.features.append(self.StatusBarCust())               \n",
    "    self.features.append(self.DisableRightClick())           \n",
    "    self.features.append(self.UsingPopupWindow())            \n",
    "    self.features.append(self.IframeRedirection())           \n",
    "    self.features.append(self.AgeofDomain())                 \n",
    "    self.features.append(self.DNSRecording())                \n",
    "    self.features.append(self.WebsiteTraffic())              \n",
    "    self.features.append(self.PageRank())                    \n",
    "    self.features.append(self.GoogleIndex())                 \n",
    "    self.features.append(self.LinksPointingToPage())         \n",
    "    self.features.append(self.StatsReport())                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c937c7",
   "metadata": {},
   "source": [
    "## 3.1. URLFeature Class: Feature Extraction Methods\n",
    "\n",
    "This cell defines the first set of feature extraction methods for the `URLFeature` class. Each method implements a specific heuristic to detect suspicious patterns in a URL, such as:\n",
    "\n",
    "- **UsingIp:** Checks if the URL uses a direct IP address instead of a domain name (often suspicious).\n",
    "- **longUrl:** Flags URLs that are unusually long, which can be a sign of phishing.\n",
    "- **shortUrl:** Detects if the URL uses a known URL-shortening service (e.g., bit.ly, tinyurl).\n",
    "- **symbol:** Looks for the '@' symbol, which can be used to obscure the real destination.\n",
    "- **redirecting:** Checks for multiple '//' in the URL path, which may indicate redirection tricks.\n",
    "- **prefixSuffix:** Flags domains with hyphens, a common phishing tactic.\n",
    "- **SubDomains:** Counts the number of subdomains; excessive subdomains can be suspicious.\n",
    "\n",
    "Each function returns **1** if the heuristic is triggered (suspicious), or **0** if not (benign). These features are essential for building a robust phishing detection model, as they capture common tricks used by attackers to deceive users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9de2ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. UsingIp\n",
    "def UsingIp(self):                                           # Check if URL is a literal IP address\n",
    "    try:\n",
    "        ipaddress.ip_address(self.url)                      # Try to parse URL as IP\n",
    "        return 1                                            # Treat IP-based URL as suspicious\n",
    "    except:\n",
    "        return 0                                            # Not an IP address\n",
    "\n",
    "# 2. longUrl\n",
    "def longUrl(self):                                          # Check if URL length is unusually long\n",
    "    if len(self.url) < 54:                                  \n",
    "        return 0                                            # Short URL → not suspicious\n",
    "    if len(self.url) >= 54 and len(self.url) <= 75:        \n",
    "        return 0                                            # Moderately long → still ok\n",
    "    return 1                                               # Very long → suspicious\n",
    "\n",
    "# 3. shortUrl\n",
    "def shortUrl(self):                                         # Detect use of URL-shortening services\n",
    "    match = re.search('bit\\\\.ly|goo\\\\.gl|shorte\\\\.st|go2l\\\\.ink|x\\\\.co|ow\\\\.ly|t\\\\.co|tinyurl|tr\\\\.im|is\\\\.gd|cli\\\\.gs|'\n",
    "                        'yfrog\\\\.com|migre\\\\.me|ff\\\\.im|tiny\\\\.cc|url4\\\\.eu|twit\\\\.ac|su\\\\.pr|twurl\\\\.nl|snipurl\\\\.com|'\n",
    "                        'short\\\\.to|BudURL\\\\.com|ping\\\\.fm|post\\\\.ly|Just\\\\.as|bkite\\\\.com|snipr\\\\.com|fic\\\\.kr|loopt\\\\.us|'\n",
    "                        'doiop\\\\.com|short\\\\.ie|kl\\\\.am|wp\\\\.me|rubyurl\\\\.com|om\\\\.ly|to\\\\.ly|bit\\\\.do|t\\\\.co|lnkd\\\\.in|'\n",
    "                        'db\\\\.tt|qr\\\\.ae|adf\\\\.ly|goo\\\\.gl|bitly\\\\.com|cur\\\\.lv|tinyurl\\\\.com|ow\\\\.ly|bit\\\\.ly|ity\\\\.im|'\n",
    "                        'q\\\\.gs|is\\\\.gd|po\\\\.st|bc\\\\.vc|twitthis\\\\.com|u\\\\.to|j\\\\.mp|buzurl\\\\.com|cutt\\\\.us|u\\\\.bb|yourls.org'\n",
    "                        '|x.co', self.url)                     # Regex for known shorteners\n",
    "    if match:\n",
    "        return 1                                            # Use of shortener → suspicious\n",
    "    return 0                                               # No shortener detected\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c868f3b",
   "metadata": {},
   "source": [
    "## 3.2. URLFeature Class: Additional Feature Extraction Methods\n",
    "\n",
    "This cell continues the implementation of the `URLFeature` class by defining more feature extraction methods. These methods analyze the URL and its components for suspicious patterns commonly associated with phishing attacks. Specifically, they check for:\n",
    "\n",
    "- The presence of the '@' symbol in the URL, which can obscure the real destination.\n",
    "- Unusual use of '//' in the URL path, which may indicate redirection tricks.\n",
    "- Hyphens in the domain name, a tactic often used by phishing sites.\n",
    "- The number of subdomains, as excessive subdomains can be suspicious.\n",
    "\n",
    "Each method returns **1** if the heuristic is triggered (indicating suspicion), or **0** if not (benign). These features are essential for building a robust phishing detection model and are widely used in academic and industry research.\n",
    "\n",
    "The code is robust and designed to handle errors gracefully, ensuring reliable feature extraction even when some URLs are malformed or incomplete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7c4603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Symbol@\n",
    "def symbol(self):                                           # Detect '@' symbol in URL\n",
    "    if re.findall(\"@\", self.url):                         \n",
    "        return 1                                            # '@' often used to obfuscate\n",
    "    return 0                                               # No '@' present\n",
    "\n",
    "# 5. Redirecting//\n",
    "def redirecting(self):                                      # Check for '//' beyond protocol\n",
    "    if self.url.rfind('//') > 6:                           \n",
    "        return 1                                            # Extra '//' → suspicious\n",
    "    return 0                                               # Normal URL structure\n",
    "\n",
    "# 6. prefixSuffix\n",
    "def prefixSuffix(self):                                     # Look for '-' in domain\n",
    "    try:\n",
    "        match = re.findall('\\\\-', self.domain)             \n",
    "        if match:\n",
    "            return 1                                        # '-' in domain → possibly phishing\n",
    "        return 0                                           # No '-' → fine\n",
    "    except:\n",
    "        return 1                                           # On error, err toward suspicious\n",
    "\n",
    "# 7. SubDomains\n",
    "def SubDomains(self):                                       # Count number of dots in URL\n",
    "    dot_count = len(re.findall(\"\\\\.\", self.url))           \n",
    "    if dot_count == 1:                                     \n",
    "        return 0                                           # Only root domain\n",
    "    elif dot_count == 2:                                   \n",
    "        return 0                                           # One subdomain\n",
    "    return 1                                               # Multiple subdomains → suspicious\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48bddbc",
   "metadata": {},
   "source": [
    "## 3.2. URLFeature Class: HTTPS and Domain Registration Features\n",
    "\n",
    "This cell adds two important feature extraction methods to the `URLFeature` class:\n",
    "\n",
    "- **Hppts:** Checks if the URL uses the HTTPS protocol. Secure (HTTPS) URLs are generally more trustworthy, but some phishing sites may still use HTTPS.\n",
    "- **DomainRegLen:** Measures the length of the domain’s registration period using WHOIS data. Domains registered for longer periods are typically more legitimate, while short-term registrations can be a red flag for phishing.\n",
    "\n",
    "Both methods are robust to missing or malformed data, ensuring reliable feature extraction even when some information is unavailable. These features are widely used in phishing detection research and are suitable for use in Kaggle competitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "246bca24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. HTTPS check\n",
    "def Hppts(self):                                            # Check URL scheme for HTTPS\n",
    "    try:\n",
    "        https = self.urlparse.scheme                      \n",
    "        if 'https' in https:\n",
    "            return 1                                        # Secure scheme\n",
    "        return 0                                           # Not HTTPS\n",
    "    except:\n",
    "        return 1                                           # Default to suspicious on error\n",
    "\n",
    "# 9. DomainRegLen\n",
    "def DomainRegLen(self):                                    # Domain registration length in months\n",
    "    try:\n",
    "        expiration_date = self.whois_response.expiration_date  # WHOIS expiration\n",
    "        creation_date = self.whois_response.creation_date    # WHOIS creation\n",
    "        try:\n",
    "            if (len(expiration_date)):\n",
    "                expiration_date = expiration_date[0]        # Handle list format\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            if (len(creation_date)):\n",
    "                creation_date = creation_date[0]            # Handle list format\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        age = (expiration_date.year - creation_date.year) * 12 + (expiration_date.month - creation_date.month)\n",
    "        if age >= 12:\n",
    "            return 1                                        # Long registration → likely benign\n",
    "        return 0                                           # Short registration → suspicious\n",
    "    except:\n",
    "        return 0                                           # On error, default to benign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4918284",
   "metadata": {},
   "source": [
    "## 3.3. URLFeature Class: Network and Domain-Based Feature Extraction\n",
    "\n",
    "This cell defines two additional methods for the `URLFeature` class:\n",
    "\n",
    "- **NonStdPort:** Checks if the URL specifies a non-standard port (e.g., `:8080`). Phishing sites sometimes use unusual ports to evade detection. If a port is specified, the feature is flagged as suspicious.\n",
    "- **HTTPSDomainURL:** Detects if the string `'https'` appears within the domain name itself (not just as the protocol). Attackers may embed `'https'` in the domain to trick users into thinking the site is secure.\n",
    "\n",
    "Both methods return **1** for benign cases and **0** for suspicious ones. These features help strengthen the detection of phishing URLs by analyzing subtle tricks used by attackers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eafbb270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. NonStdPort\n",
    "def NonStdPort(self):                                       # Detect non-standard port in domain\n",
    "    try:\n",
    "        port = self.domain.split(\":\")                      \n",
    "        if len(port) > 1:\n",
    "            return 0                                        # Non‑std port specified → suspicious\n",
    "        return 1                                           # No port → benign\n",
    "    except:\n",
    "        return 0                                           # On error, default to suspicious\n",
    "\n",
    "# 12. HTTPSDomainURL\n",
    "def HTTPSDomainURL(self):                                   # Check if 'https' appears in domain string itself\n",
    "    try:\n",
    "        if 'https' in self.domain:\n",
    "            return 0                                        # Suspicious embedding of 'https'\n",
    "        return 1                                           # Domain clean\n",
    "    except:\n",
    "        return 0                                           # On error, default to suspicious\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36750750",
   "metadata": {},
   "source": [
    "Certainly! Here’s a clear markdown explanation for the next Python cell, suitable for Kaggle documentation:\n",
    "\n",
    "---\n",
    "\n",
    "## 3.4. URLFeature Class: Abnormal URL and Webpage Content Features\n",
    "\n",
    "This cell implements several feature extraction methods that analyze the content and behavior of the web page associated with a URL. These features help detect suspicious activity by examining the page’s HTML, JavaScript, and HTTP response:\n",
    "\n",
    "- **AbnormalURL:** Compares the web page content to WHOIS data to detect abnormal similarities.\n",
    "- **WebsiteForwarding:** Checks how many times the page redirects, as excessive redirects can be suspicious.\n",
    "- **StatusBarCust:** Looks for JavaScript that modifies the browser’s status bar, a common phishing trick.\n",
    "- **DisableRightClick:** Detects scripts that disable right-click, often used to prevent users from inspecting the page.\n",
    "- **UsingPopupWindow:** Flags the use of JavaScript pop-up alerts, which can be used for phishing.\n",
    "- **IframeRedirection:** Checks for the presence of iframes, which can hide malicious content.\n",
    "\n",
    "Each method returns **1** if the suspicious pattern is detected, or **0** otherwise. These features are widely used in phishing detection research and are robust to errors or missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b466567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 18. AbnormalURL\n",
    "def AbnormalURL(self):                                      # Compare page content to WHOIS text\n",
    "    try:\n",
    "        if self.response.text == self.whois_response:      \n",
    "            return 1                                        # Abnormal if identical\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 19. WebsiteForwarding\n",
    "def WebsiteForwarding(self):                                # Check redirect history length\n",
    "    try:\n",
    "        if len(self.response.history) <= 1:\n",
    "            return 1                                        # No redirects → benign\n",
    "        elif len(self.response.history) <= 4:\n",
    "            return 0                                        # Few redirects → suspicious\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 20. StatusBarCust\n",
    "def StatusBarCust(self):                                    # Detect JavaScript status‑bar modification\n",
    "    try:\n",
    "        if re.findall(\"<script>.+onmouseover.+</script>\", self.response.text):\n",
    "            return 1                                        # Found suspicious script\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 21. DisableRightClick\n",
    "def DisableRightClick(self):                                # Detect script disabling right‑click\n",
    "    try:\n",
    "        if re.findall(r\"event.button ?== ?2\", self.response.text):\n",
    "            return 1                                        # Right‑click blocked\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 22. UsingPopupWindow\n",
    "def UsingPopupWindow(self):                                 # Detect JavaScript alert pop‑ups\n",
    "    try:\n",
    "        if re.findall(r\"alert\\(\", self.response.text):\n",
    "            return 1                                        # Pop‑up usage → suspicious\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 23. IframeRedirection\n",
    "def IframeRedirection(self):                                # Detect iframes in page\n",
    "    try:\n",
    "        if re.findall(r\"[<iframe>|<frameBorder>]\", self.response.text):\n",
    "            return 1                                        # Iframe present → suspicious\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bd5fd4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.5. URLFeature Class: Domain Age, DNS, and Traffic Feature Methods\n",
    "\n",
    "This cell defines the final set of feature extraction methods for the `URLFeature` class, focusing on domain reputation and web popularity signals:\n",
    "\n",
    "- **AgeofDomain:** Calculates how many months have passed since the domain was registered. Older domains are generally more trustworthy.\n",
    "- **DNSRecording:** Measures the age of the DNS record, flagging domains with recent DNS entries as potentially suspicious.\n",
    "- **WebsiteTraffic:** Uses Alexa rank to estimate the website’s popularity. Highly ranked (popular) sites are less likely to be phishing.\n",
    "- **PageRank:** Queries an external service to determine the global PageRank of the site. Higher ranks indicate more reputable sites.\n",
    "- **GoogleIndex:** Checks if the URL is indexed by Google, as legitimate sites are usually indexed.\n",
    "- **LinksPointingToPage:** Counts the number of hyperlinks on the page; phishing sites often have few or no outbound links.\n",
    "- **StatsReport:** Compares the domain and its IP address against lists of known phishing hosts and IPs.\n",
    "\n",
    "Each method returns **1** for benign (trustworthy) cases and **0** for suspicious ones. These features are widely used in phishing detection research and help improve the robustness of your model for Kaggle competitions. The code is designed to handle missing or malformed data gracefully, ensuring reliable feature extraction even when some information is unavailable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a8ae6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24. AgeofDomain\n",
    "def AgeofDomain(self):                                      # Months since domain creation\n",
    "    try:\n",
    "        creation_date = self.whois_response.creation_date\n",
    "        try:\n",
    "            if (len(creation_date)):\n",
    "                creation_date = creation_date[0]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        today = date.today()                               # Current date\n",
    "        age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "        if age >= 6:\n",
    "            return 1                                        # Older than 6 months → benign\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 25. DNSRecording\n",
    "def DNSRecording(self):                                     # Same as AgeofDomain (DNS record age)\n",
    "    try:\n",
    "        creation_date = self.whois_response.creation_date\n",
    "        try:\n",
    "            if (len(creation_date)):\n",
    "                creation_date = creation_date[0]\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        today = date.today()\n",
    "        age = (today.year - creation_date.year) * 12 + (today.month - creation_date.month)\n",
    "        if age >= 6:\n",
    "            return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49865efb",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3.6. URLFeature Class: Website Traffic, PageRank, Google Index, and Reputation Features\n",
    "\n",
    "This cell implements the final set of feature extraction methods for the `URLFeature` class, focusing on web reputation and popularity signals:\n",
    "\n",
    "- **WebsiteTraffic:** Uses Alexa rank to estimate the website’s popularity. Highly ranked (popular) sites are less likely to be phishing.\n",
    "- **PageRank:** Queries an external service to determine the global PageRank of the site. Higher ranks indicate more reputable sites.\n",
    "- **GoogleIndex:** Checks if the URL is indexed by Google, as legitimate sites are usually indexed.\n",
    "- **LinksPointingToPage:** Counts the number of hyperlinks on the page; phishing sites often have few or no outbound links.\n",
    "- **StatsReport:** Compares the domain and its IP address against lists of known phishing hosts and IPs.\n",
    "\n",
    "Each method returns **1** for benign (trustworthy) cases and **0** for suspicious ones. These features are widely used in phishing detection research and help improve the robustness of your model for Kaggle competitions. The code is designed to handle missing or malformed data gracefully, ensuring reliable feature extraction even when some information is unavailable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e1e66d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 26. WebsiteTraffic\n",
    "def WebsiteTraffic(self):                                   # Fetch Alexa reach rank\n",
    "    try:\n",
    "        rank = BeautifulSoup(urllib.request.urlopen(\"http://data.alexa.com/data?cli=10&dat=s&url=\" + url).read(),\n",
    "                                \"xml\").find(\"REACH\")['RANK']     # Extract RANK attribute\n",
    "        if (int(rank) < 100000):\n",
    "            return 1                                        # Popular site → benign\n",
    "        return 0                                           # Low traffic → suspicious\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 27. PageRank\n",
    "def PageRank(self):                                         # Query external PageRank service\n",
    "    try:\n",
    "        prank_checker_response = requests.post(\"https://www.checkpagerank.net/index.php\", {\"name\": self.domain})\n",
    "        global_rank = int(re.findall(r\"Global Rank: ([0-9]+)\", rank_checker_response.text)[0])\n",
    "        if global_rank > 0 and global_rank < 100000:\n",
    "            return 1\n",
    "        return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 28. GoogleIndex\n",
    "def GoogleIndex(self):                                      # Use Google search to detect indexing\n",
    "    try:\n",
    "        site = search(self.url, 5)                         # Up to 5 results\n",
    "        if site:\n",
    "            return 1                                       # Indexed → benign\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 1                                           # On error, err toward benign\n",
    "\n",
    "# 29. LinksPointingToPage\n",
    "def LinksPointingToPage(self):                             # Count hyperlink tags in page\n",
    "    try:\n",
    "        number_of_links = len(re.findall(r\"<a href=\", self.response.text))\n",
    "        if number_of_links == 0:\n",
    "            return 1                                       # No links → suspicious\n",
    "        elif number_of_links <= 2:\n",
    "            return 0\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# 30. StatsReport\n",
    "def StatsReport(self):                                      # Check against known phishing hosts/IPs\n",
    "    try:\n",
    "        url_match = re.search(\n",
    "            'at\\\\.ua|usa\\\\.cc|baltazarpresentes\\\\.com\\\\.br|pe\\\\.hu|esy\\\\.es|hol\\\\.es|sweddy\\\\.com|myjino\\\\.ru|96\\\\.lt|ow\\\\.ly',\n",
    "            url)                                          # Known bad domains\n",
    "        ip_address = socket.gethostbyname(self.domain)     # Resolve domain to IP\n",
    "        ip_match = re.search(\n",
    "            '146\\\\.112\\\\.61\\\\.108|213\\\\.174\\\\.157\\\\.151|121\\\\.50\\\\.168\\\\.88|192\\\\.185\\\\.217\\\\.116|78\\\\.46\\\\.211\\\\.158|181\\\\.174\\\\.165\\\\.13|46\\\\.242\\\\.145\\\\.103|121\\\\.50\\\\.168\\\\.40|83\\\\.125\\\\.22\\\\.219|46\\\\.242\\\\.145\\\\.98|'\n",
    "            '107\\\\.151\\\\.148\\\\.44|107\\\\.151\\\\.148\\\\.107|64\\\\.70\\\\.19\\\\.203|199\\\\.184\\\\.144\\\\.27|107\\\\.151\\\\.148\\\\.108|107\\\\.151\\\\.148\\\\.109|119\\\\.28\\\\.52\\\\.61|54\\\\.83\\\\.43\\\\.69|52\\\\.69\\\\.166\\\\.231|216\\\\.58\\\\.192\\\\.225|'\n",
    "            '118\\\\.184\\\\.25\\\\.86|67\\\\.208\\\\.74\\\\.71|23\\\\.253\\\\.126\\\\.58|104\\\\.239\\\\.157\\\\.210|175\\\\.126\\\\.123\\\\.219|141\\\\.8\\\\.224\\\\.221|10\\\\.10\\\\.10\\\\.10|43\\\\.229\\\\.108\\\\.32|103\\\\.232\\\\.215\\\\.140|69\\\\.172\\\\.201\\\\.153|'\n",
    "            '216\\\\.218\\\\.185\\\\.162|54\\\\.225\\\\.104\\\\.146|103\\\\.243\\\\.24\\\\.98|199\\\\.59\\\\.243\\\\.120|31\\\\.170\\\\.160\\\\.61|213\\\\.19\\\\.128\\\\.77|62\\\\.113\\\\.226\\\\.131|208\\\\.100\\\\.26\\\\.234|195\\\\.16\\\\.127\\\\.102|195\\\\.16\\\\.127\\\\.157|'\n",
    "            '34\\\\.196\\\\.13\\\\.28|103\\\\.224\\\\.212\\\\.222|172\\\\.217\\\\.4\\\\.225|54\\\\.72\\\\.9\\\\.51|192\\\\.64\\\\.147\\\\.141|198\\\\.200\\\\.56\\\\.183|23\\\\.253\\\\.164\\\\.103|52\\\\.48\\\\.191\\\\.26|52\\\\.214\\\\.197\\\\.72|87\\\\.98\\\\.255\\\\.18|209\\\\.99\\\\.17\\\\.27|'\n",
    "            '216\\\\.38\\\\.62\\\\.18|104\\\\.130\\\\.124\\\\.96|47\\\\.89\\\\.58\\\\.141|78\\\\.46\\\\.211\\\\.158|54\\\\.86\\\\.225\\\\.156|54\\\\.82\\\\.156\\\\.19|37\\\\.157\\\\.192\\\\.102|204\\\\.11\\\\.56\\\\.48|110\\\\.34\\\\.231\\\\.42',\n",
    "            ip_address)                                  # Known bad IPs\n",
    "        if url_match:\n",
    "            return 0                                       # Known bad domain → phishing\n",
    "        elif ip_match:\n",
    "            return 0                                       # Known bad IP → phishing\n",
    "        return 1                                           # Otherwise → benign\n",
    "    except:\n",
    "        return 1                                           # On error, err toward benign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9585fa4f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Helper Functions: Feature Extraction and Testing\n",
    "\n",
    "This cell provides utility functions to streamline feature extraction and testing for your phishing detection project:\n",
    "\n",
    "- **getFeaturesList:**  \n",
    "    Returns the list of 30 computed features for a given URL, making it easy to use the extracted data in downstream analysis or machine learning models.\n",
    "\n",
    "- **test_feature_extraction:**  \n",
    "    A convenient function to quickly test feature extraction on any URL. It creates a `URLFeature` object, extracts all features, and prints each feature’s value in a readable format. This is especially useful for debugging or demonstrating your feature extraction pipeline.\n",
    "\n",
    "- **Sample Usage:**  \n",
    "    The cell includes an example that runs the feature extraction on `https://youtube.com` if the script is executed directly. This demonstrates how to use the helper for rapid prototyping or validation.\n",
    "\n",
    "These helpers are essential for integrating your feature extraction logic into Kaggle notebooks, enabling efficient experimentation and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc90b665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred during feature extraction: URLFeature() takes no arguments\n"
     ]
    }
   ],
   "source": [
    "def getFeaturesList(self):                                # Return the computed feature list\n",
    "    return self.features                                 \n",
    "\n",
    "def test_feature_extraction(url):                            # Helper to test on a single URL\n",
    "    try:\n",
    "        extractor = URLFeature(url)                          # Instantiate extractor\n",
    "        print(f\"Extracted features for URL: {url}\")          # Header printout\n",
    "        for i, feature in enumerate(extractor.features, start=1):\n",
    "            print(f\"Feature {i}: {feature}\")                 # Print each feature value\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during feature extraction: {e}\")  # Error handling\n",
    "\n",
    "# Test with a sample URL\n",
    "if __name__ == \"__main__\":\n",
    "    sample_url = \"https://youtube.com\"                       # Example URL\n",
    "    test_feature_extraction(sample_url)                      # Run the test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
